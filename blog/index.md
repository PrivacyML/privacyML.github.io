---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
title:
permalink: /
hero: "blog/assets/img/eva-title.png"
# hero: "assets/img/eva-title.png" # for local deployment
---
[//]: # Through our work on evaluations of privacy technology for machine learning, we found that disparate communities in ML training, large model R&D, and safety and policy urgently want to have an overview on the state of privacy and evaluations that suit their purpose, especially as generative AI technologies become important. However, there is no single technology that fits all use cases, and without in-depth knowledge of both machine learning and cryptography, it can be very difficult to initiate research in this impactful and fast-moving field. We hope that clarifying the technologies for this purpose will help towards effective scientific coordination.

# Evaluating AI Privacy: A Knowledge Gap
We observe that the ML community cannot sufficiently access privacy tech. People interested in safe ML topics such as model alignment often do not have a clear understanding of cryptography-based techniques when applied to ML.

On the other hand, cryptographers want to apply their knowledge, especially with practical security management, to machine learning systems. Yet they face the problem of a completely different mindset from machine learning researchers who currently drive the development of these systems.

These communities do not engage with each other, partly because they do not have a shared common ground. This tutorial can bridge the gap between cryptography and effective decentralized ML training and evaluation.

Join us at NeurIPS 2024 for a tutorial on Privacy ML: Meaningful-Privacy Preserving Machine Learning and How to Evaluate AI Privacy.

# Save the Date
## Dec 10, 2024. Vancouver Convention Center, British Columbia, Canada.
{% include_relative add_event.html %}