---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
title:
permalink: /
hero: "assets/img/eva-title.jpg"
---
[//]: # Through our work on evaluations of privacy technology for machine learning, we found that disparate communities in ML training, large model R&D, and safety and policy urgently want to have an overview on the state of privacy and evaluations that suit their purpose, especially as generative AI technologies become important. However, there is no single technology that fits all use cases, and without in-depth knowledge of both machine learning and cryptography, it can be very difficult to initiate research in this impactful and fast-moving field. We hope that clarifying the technologies for this purpose will help towards effective scientific coordination.
# Why Tutorial?
Disparate communities in ML Research, large model R&D, and Safety and Policy urgently want to have an overview on the state of privacy and evaluations that suit their purpose, especially as generative AI technologies become important. Yet, no single technology fits all use cases, and without in-depth knowledge of both machine learning and cryptography, it can be very difficult to initiate research in this impactful and fast-moving field. We hope that clarifying the technologies for this purpose will help towards effective scientific coordination.

Join us at NeurIPS 2024 for a tutorial on Privacy ML: Meaningful-Privacy Preserving Machine Learning and How to Evaluate AI Privacy.

# Save the Date
## Dec 10, 2024. Vancouver Convention Center, British Columbia, Canada.

# Evaluating AI Privacy: A Knowledge Gap
We observe that the ML community cannot sufficiently access privacy tech. People interested in safe ML topics such as model alignment often do not have a clear understanding of cryptography-based techniques when applied to ML.

On the other hand, cryptographers want to apply their knowledge, especially with practical security management, to machine learning systems. Yet they face the problem of a completely different mindset from machine learning researchers who currently drive the development of these systems.

These communities do not engage with each other, partly because they do not have a shared common ground. This tutorial can bridge the gap between cryptography and effective decentralized ML training and evaluation.

# Abstract
## Meaningful Privacy-Preserving Machine Learning and How Do We Evaluate AI Privacy?
In the world of large model development, model details and training data are increasingly closed down, pushing privacy to the forefront of machine learning – how do we protect privacy of the data used to train the model, permitting more widespread data sharing collaborations? How will individuals trust these technologies with their data? How do we verify that the integration of individual’s data is both useful to the rest of the participating federation, and, more importantly - safe for the data owner? How do the regulations integrate into this complex infrastructure?

These open questions require a multitude of considerations between the incentives of model development,the  data owning parties, and the overseeing agencies. Many cryptographic solutions target these incentives problems, but  are they covering all essential components of trustworthy data sharing? Are they practical, or likely to be practical soon?

In this tutorial, we attempt to answer questions regarding specific capabilities of privacy technologies in three parts: 1. overarching incentive issues with respect to data and evaluations, 2. Where cryptographic and optimisation solutions can help; for evaluations, we delve deep into secure computation and machine unlearning. 3. Cultural, societal, and research agendas relating to practically implementing these technologies.

We hope that, by identifying the boundaries of the use of privacy technologies, and providing a technical and structured framework for reasoning over these issues, we could empower the general audience to integrate these principles (and practical solutions) into their existing research. Those already interested in applying the technology can gain a deeper, hands-on understanding of implementation useful for modeling and developing incentive-compatible solutions for their own work.