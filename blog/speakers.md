---
layout: page
title: About Us
permalink: /about/
---
Our tutorial at NeurIPS is [here](https://neurips.cc/virtual/2024/tutorial/99533).

# Mimee Xu
![headshot_mimeexu]({{ site.baseurl }}{% link /assets/img/mimee.jpg %})

​Mimee Xu is a 6th year PhD student at NYU’s Courant Institute, working under Prof. Leon Bottou on the intersection of Privacy and Security of ML. During her PhD, she interned at Facebook AI Research and ByteDance Machine Learning. Previously, she worked as a Research Engineer/Machine Learning Engineer/Software engineer at UnifyID, Baidu SVAIL, and Google Chrome. She organized the [ML for Systems](mlforsystems.org) workshop at NeurIPS for 5 years.

# Fazl Barez
![headshot_fazlbarez]({{ site.baseurl }}{% link /assets/img/fazl.jpg %})

Fazl Barez is a Research Fellow at Torr Vision Group (TVG), University of Oxford, where he works on topics related to AI safety. Additionally, Fazl also holds affiliations with Kruger AI Safety Lab (KASL), the Centre for the Study of Existential Risk at University of Cambridge and Future of Life Institute.  Previously, Fazl  worked as Technology and Security Policy Fellow at RAND, on Interpretability at Amazon and The DataLab, safe recommender systems at Huawei, and on building a finance tool for budget management for economic scenario forecasting at Natwest Group. Fazl holds a PhD in Artificial Intelligence Safety and has previously organized the [Mechanistic Interpretability](https://icml2024mi.pages.dev/) workshop at ICML, and an [Inverse Scaling](https://www.aclweb.org/portal/content/first-call-papers-workshop-scaling-behavior-large-language-models-scale-llm-2024) workshop at EACL.

# Dmitrii Usynin
![headshot_dmitriiusynin]({{ site.baseurl }}{% link /assets/img/dima.png %})

Dmitrii Usynin is a Research Scientist at Oblivious and a final year PhD student in a Joint Academy of Doctoral Studies (JADS) at Imperial College London and TU Munich. His research interests lie on the intersection of collaborative machine learning (CML) and trustworthy artificial intelligence. In particular, he is interested in topics such as privacy-preserving machine learning (PPML), attacks on CML, federated learning and memorisation in ML. Previously he was a ML Researcher at Microsoft Research and Brave Research. At MSR he worked on memorisation and factuality for radiology-facing LLMs. At Brave Research he worked on principled selection of clients and data in resource-constrained federated learning. In addition he was also a Privacy Researcher at OpenMined, working on federated learning and differential privacy in healthcare.